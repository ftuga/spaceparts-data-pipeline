{"cells":[{"cell_type":"markdown","source":["## Bronze Layer - Incremental Load (Azure SQL Database)\n","- **Purpose**: Extract data from SpaceParts training database\n","- **Layer**: Bronze (Raw Data)\n","- **Load Type**: Incremental"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"24987338-cbab-46c0-8d70-38307b058677"},{"cell_type":"markdown","source":["---\n","### Parámetros\n","---\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"53a31b9a-462f-4964-977f-6e89bf803f28"},{"cell_type":"code","source":["import os\n","from datetime import datetime, timedelta\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","\n","execution_date = os.environ.get(\"execution_date\", datetime.now().isoformat())\n","lookback_days = int(os.environ.get(\"lookback_days\", \"1\"))  # Días hacia atrás para la carga incremental"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:09:54.389537Z","session_start_time":null,"execution_start_time":"2025-09-18T21:09:54.3905929Z","execution_finish_time":"2025-09-18T21:09:54.8289482Z","parent_msg_id":"433e948c-9876-460e-9b60-810f8c25ad07"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"82b701d4-310e-4ee8-89f3-66aa772f2e62"},{"cell_type":"markdown","source":["---\n","### Dependencias\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"74d0c84f-cb16-4e37-a671-a3ed7a54e534"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from pyspark import StorageLevel\n","from datetime import datetime, timedelta\n","import logging\n","import pandas as pd\n","import re, unicodedata\n","from collections import defaultdict\n","from pyspark.sql.functions import col, max as fmax"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":30,"statement_ids":[30],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:39:37.4904882Z","session_start_time":null,"execution_start_time":"2025-09-18T21:39:37.4916097Z","execution_finish_time":"2025-09-18T21:39:37.8195501Z","parent_msg_id":"a7c6bb36-5d5f-4362-b45d-24c09e0dcacd"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 30, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8bdcb37a-0de1-40ea-95b8-d28fd86408fa"},{"cell_type":"markdown","source":["---\n","### Configuraciones de optimización\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4fad564b-c116-4e4c-8d02-6ee53faefad7"},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n","spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n","spark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n","spark.conf.set(\"spark.databricks.delta.autoCompact.enabled\", \"true\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:09:56.7265517Z","session_start_time":null,"execution_start_time":"2025-09-18T21:09:56.7276337Z","execution_finish_time":"2025-09-18T21:09:57.0240984Z","parent_msg_id":"4b94caad-7370-41e4-ba27-5e0f43660ebb"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f6ac34b3-1b28-4263-a528-0192ef113a8e"},{"cell_type":"markdown","source":["---\n","### Configuraciones de los Logs\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"91a0bf4a-ba01-4934-b2a1-622f458aa2fb"},{"cell_type":"code","source":["logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:09:58.3731889Z","session_start_time":null,"execution_start_time":"2025-09-18T21:09:58.3742682Z","execution_finish_time":"2025-09-18T21:09:58.7150528Z","parent_msg_id":"a5bd7d51-ddeb-4bf2-87c9-55db940f130c"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fe909f74-f9ef-41aa-a7c3-8ba0b8a7ba87"},{"cell_type":"markdown","source":["---\n","### Credenciales de conexión\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"382d5bdf-a9cb-47ba-9df7-b7b0f86797b6"},{"cell_type":"code","source":["class BronzeIncrementalLoader:\n","    def __init__(self, spark_session):\n","        self.spark = spark_session\n","        self.server = \"te3-training-eu.database.windows.net\"\n","        self.database = \"SpacePartsCoDW\"\n","        self.username = \"dwreader@te3-training-eu\"\n","        self.password = \"TE3#reader!\"\n","    \n","    def get_jdbc_connection_properties(self):\n","        jdbc_url = f\"jdbc:sqlserver://{self.server}:1433;database={self.database};encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\n","    \n","        return {\n","            \"url\": jdbc_url,\n","            \"user\": self.username,\n","            \"password\": self.password,\n","            \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n","        }\n","    \n","    def get_last_execution_timestamp(self, table_name: str):\n","        \"\"\"Obtiene la última fecha de ejecución exitosa para una tabla\"\"\"\n","        try:\n","            if not self.spark._jsparkSession.catalog().tableExists(\"bronze_incremental_control\"):\n","                bronze_table_name = clean_bronze_table_name(*table_name.split('.'))\n","                if self.spark._jsparkSession.catalog().tableExists(bronze_table_name):\n","                    max_date = self.spark.table(bronze_table_name).agg(max(\"dwcreateddate\")).collect()[0][0]\n","                    logger.info(f\"Usando fecha máxima de tabla bronze para {table_name}: {max_date}\")\n","                    return max_date\n","                return None\n","                \n","            control_df = self.spark.table(\"bronze_incremental_control\")\n","            last_run = control_df.filter(\n","                (col(\"table_name\") == table_name) & \n","                (col(\"status\") == \"success\")\n","            ).orderBy(col(\"execution_timestamp\").desc()).limit(1).collect()\n","            \n","            if last_run:\n","                return last_run[0][\"last_extracted_timestamp\"]\n","            else:\n","                bronze_table_name = clean_bronze_table_name(*table_name.split('.'))\n","                if self.spark._jsparkSession.catalog().tableExists(bronze_table_name):\n","                    max_date = self.spark.table(bronze_table_name).agg(max(\"dwcreateddate\")).collect()[0][0]\n","                    logger.info(f\"Primera ejecución incremental para {table_name}. Usando fecha máxima: {max_date}\")\n","                    return max_date\n","                return None\n","        except Exception as e:\n","            logger.warning(f\"No se pudo obtener timestamp para {table_name}: {e}\")\n","            return None\n","    \n","    def update_execution_control(self, table_name: str, last_extracted_timestamp, status: str, record_count: int = 0):\n","        \"\"\"Actualiza la tabla de control con información de la ejecución\"\"\"\n","        control_data = [(\n","            table_name,\n","            execution_date,\n","            datetime.now(),\n","            last_extracted_timestamp,\n","            status,\n","            record_count\n","        )]\n","        \n","        control_schema = StructType([\n","            StructField(\"table_name\", StringType(), True),\n","            StructField(\"execution_id\", StringType(), True),\n","            StructField(\"execution_timestamp\", TimestampType(), True),\n","            StructField(\"last_extracted_timestamp\", TimestampType(), True),\n","            StructField(\"status\", StringType(), True),\n","            StructField(\"record_count\", IntegerType(), True)\n","        ])\n","        \n","        control_df = self.spark.createDataFrame(control_data, control_schema)\n","        control_df.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").saveAsTable(\"bronze_incremental_control\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:10:39.1014983Z","session_start_time":null,"execution_start_time":"2025-09-18T21:10:39.10265Z","execution_finish_time":"2025-09-18T21:10:39.4133786Z","parent_msg_id":"da76dd15-1812-45ab-9208-12e708efd43c"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a390f8ed-3f80-41bd-bb86-0a1381207770"},{"cell_type":"code","source":["bronze_loader = BronzeIncrementalLoader(spark)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:10:42.5737691Z","session_start_time":null,"execution_start_time":"2025-09-18T21:10:42.5748962Z","execution_finish_time":"2025-09-18T21:10:42.9429898Z","parent_msg_id":"3a44e9b9-d343-4d41-8916-14b2edb3c2d2"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 12, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9e0e19a7-d9ba-47d7-a2ba-d3bba2dca4e7"},{"cell_type":"markdown","source":["---\n","### Obtener lista de tablas\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2008cd18-c9eb-4bef-9a64-3cafc162ecb8"},{"cell_type":"code","source":["try:\n","    tables_query = \"\"\"(\n","        SELECT TABLE_SCHEMA, TABLE_NAME \n","        FROM INFORMATION_SCHEMA.TABLES \n","        WHERE TABLE_TYPE='BASE TABLE' \n","        AND TABLE_SCHEMA IN ('dim', 'fact')\n","    ) as tables_query\"\"\"\n","    \n","    connection_props = bronze_loader.get_jdbc_connection_properties()\n","    \n","    tables_df = spark.read \\\n","        .format(\"jdbc\") \\\n","        .option(\"url\", connection_props[\"url\"]) \\\n","        .option(\"dbtable\", tables_query) \\\n","        .option(\"user\", connection_props[\"user\"]) \\\n","        .option(\"password\", connection_props[\"password\"]) \\\n","        .option(\"driver\", connection_props[\"driver\"]) \\\n","        .load()\n","    \n","    tables_df = tables_df.orderBy(\"TABLE_SCHEMA\", \"TABLE_NAME\")    \n","    tables_list = tables_df.collect()\n","    \n","    print(f\"Se encontraron {len(tables_list)} tablas para carga incremental:\")\n","    for row in tables_list:\n","        print(f\"  - {row.TABLE_SCHEMA}.{row.TABLE_NAME}\")\n","\n","except Exception as e:\n","    print(f\"Error obteniendo lista de tablas: {str(e)}\")\n","    tables_list = [\n","        type('obj', (object,), {'TABLE_SCHEMA': 'dim', 'TABLE_NAME': 'Brands'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'dim', 'TABLE_NAME': 'Budget-Rate'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'dim', 'TABLE_NAME': 'Customers'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'dim', 'TABLE_NAME': 'Employees'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'dim', 'TABLE_NAME': 'Exchange-Rate'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'dim', 'TABLE_NAME': 'Invoice-DocType'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'dim', 'TABLE_NAME': 'Order-DocType'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'dim', 'TABLE_NAME': 'Order-Status'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'dim', 'TABLE_NAME': 'Products'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'dim', 'TABLE_NAME': 'Regions'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'fact', 'TABLE_NAME': 'Budget'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'fact', 'TABLE_NAME': 'Forecast'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'fact', 'TABLE_NAME': 'Invoices'}),\n","        type('obj', (object,), {'TABLE_SCHEMA': 'fact', 'TABLE_NAME': 'Orders'})\n","    ]"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:11:13.983598Z","session_start_time":null,"execution_start_time":"2025-09-18T21:11:13.9847342Z","execution_finish_time":"2025-09-18T21:11:21.8100197Z","parent_msg_id":"9690cf3d-45e2-447b-b540-7f0616941ea0"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 13, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Se encontraron 14 tablas para carga incremental:\n  - dim.Brands\n  - dim.Budget-Rate\n  - dim.Customers\n  - dim.Employees\n  - dim.Exchange-Rate\n  - dim.Invoice-DocType\n  - dim.Order-DocType\n  - dim.Order-Status\n  - dim.Products\n  - dim.Regions\n  - fact.Budget\n  - fact.Forecast\n  - fact.Invoices\n  - fact.Orders\n"]}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8fbb642c-9c0c-4dea-8600-be99da745576"},{"cell_type":"markdown","source":["---\n","### Funciones de normalización (mantenidas del original)\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2ec9f9e2-013d-4d7c-98ec-b377a84c9452"},{"cell_type":"code","source":["FORBIDDEN_CHARS = r\"[ ,;{}\\(\\)\\n\\t=]+\"\n","RESERVED = {\n","    \"select\",\"from\",\"where\",\"group\",\"order\",\"by\",\"having\",\"limit\",\"offset\",\n","    \"and\",\"or\",\"not\",\"as\",\"on\",\"join\",\"inner\",\"left\",\"right\",\"full\",\"cross\",\n","    \"desc\",\"asc\",\"table\",\"column\",\"index\",\"view\",\"database\",\"schema\",\"create\",\n","    \"drop\",\"alter\",\"insert\",\"update\",\"delete\",\"merge\",\"into\",\"values\",\"set\",\n","    \"case\",\"when\",\"then\",\"else\",\"end\",\"union\",\"all\",\"distinct\",\"true\",\"false\",\n","    \"null\"\n","}\n","\n","def strip_accents(text: str) -> str:\n","    t = unicodedata.normalize(\"NFKD\", str(text))\n","    return \"\".join([c for c in t if not unicodedata.combining(c)])\n","\n","def clean_identifier(name: str) -> str:\n","    if name is None: return \"col\"\n","    s = strip_accents(str(name).strip())\n","    s = re.sub(FORBIDDEN_CHARS, \"_\", s)\n","    s = s.replace(\".\", \"_\").replace(\"-\", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n","    s = re.sub(r\"[^0-9a-zA-Z_]\", \"\", s)\n","    s = re.sub(r\"_+\", \"_\", s).strip(\"_\").lower()\n","    if re.match(r\"^[0-9]\", s): s = \"c_\" + s\n","    if s in RESERVED: s = s + \"_col\"\n","    if not s: s = \"col\"\n","    return s[:128]\n","\n","def split_schema_table(table_name: str):\n","    val = str(table_name).strip()\n","    if \".\" in val:\n","        s, t = val.split(\".\", 1)\n","    else:\n","        s, t = \"dbo\", val\n","    return s.strip(), t.strip()\n","\n","def clean_bronze_table_name(schema: str, table: str) -> str:\n","    schema_c = clean_identifier(schema)\n","    table_c  = clean_identifier(table)\n","    return f\"bronze_{schema_c}_{table_c}\"\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:11:42.6515218Z","session_start_time":null,"execution_start_time":"2025-09-18T21:11:42.6527751Z","execution_finish_time":"2025-09-18T21:11:42.9764284Z","parent_msg_id":"df43f295-5198-4de8-bd08-5f47bdb93eac"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"016d6a25-851b-4616-b412-51c606f46652"},{"cell_type":"markdown","source":["---\n","### Extracción incremental\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"aff2a155-fc88-45a4-9305-50e5c0ad3270"},{"cell_type":"code","source":["if not hasattr(BronzeIncrementalLoader, \"extract_table_incremental\"):\n","    def _extract_table_incremental(self, schema: str, table: str, timestamp_column: str = \"DWCreatedDate\"):\n","        \"\"\"Extrae datos incrementales basado en la última fecha de carga\"\"\"\n","        props = self.get_jdbc_connection_properties()\n","        full_name = f\"[{schema}].[{table}]\"\n","        last_timestamp = self.get_last_execution_timestamp(f\"{schema}.{table}\")\n","        \n","        if last_timestamp is None:\n","            logger.info(f\"Primera carga para {full_name} - extrayendo todos los datos\")\n","            query = f\"SELECT * FROM {full_name}\"\n","            load_type = \"initial\"\n","        else:\n","            safe_timestamp = last_timestamp - timedelta(hours=1)  # 1 hora de overlap\n","            logger.info(f\"Carga incremental para {full_name} desde {safe_timestamp}\")\n","            query = f\"\"\"\n","                SELECT * FROM {full_name} \n","                WHERE {timestamp_column} > '{safe_timestamp.strftime('%Y-%m-%d %H:%M:%S')}'\n","            \"\"\"\n","            load_type = \"incremental\"\n","\n","        df = (\n","            self.spark.read.format(\"jdbc\")\n","            .option(\"url\", props[\"url\"])\n","            .option(\"user\", props[\"user\"])\n","            .option(\"password\", props[\"password\"])\n","            .option(\"driver\", props[\"driver\"])\n","            .option(\"query\", query)\n","            .option(\"fetchsize\", \"10000\")\n","            .load()\n","        )\n","        \n","        return df, load_type\n","    \n","    BronzeIncrementalLoader.extract_table_incremental = _extract_table_incremental\n","\n","if not hasattr(BronzeIncrementalLoader, \"save_bronze_table_incremental\"):\n","    def _save_bronze_table_incremental(self, df_spark, bronze_table_name: str, load_type: str) -> int:\n","        \"\"\"Guarda datos en modo incremental - siempre usa append ya que asume full load previo\"\"\"\n","        record_count = df_spark.count()\n","        \n","        if record_count == 0:\n","            logger.info(f\"No hay datos nuevos para {bronze_table_name}\")\n","            return 0\n","        \n","        table_exists = self.spark._jsparkSession.catalog().tableExists(bronze_table_name)\n","        \n","        if not table_exists:\n","            logger.warning(f\"Tabla {bronze_table_name} no existe. ¿Se ejecutó el full load primero?\")\n","            df_spark.write.mode(\"overwrite\").format(\"delta\").saveAsTable(bronze_table_name)\n","            logger.info(f\"Tabla creada para {bronze_table_name}: {record_count:,} records\")\n","        else:\n","            df_spark.write.mode(\"append\").format(\"delta\").saveAsTable(bronze_table_name)\n","            logger.info(f\"Datos incrementales agregados a {bronze_table_name}: {record_count:,} records\")\n","            \n","        return record_count\n","    \n","    BronzeIncrementalLoader.save_bronze_table_incremental = _save_bronze_table_incremental\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:12:22.4740224Z","session_start_time":null,"execution_start_time":"2025-09-18T21:12:22.4753005Z","execution_finish_time":"2025-09-18T21:12:22.8697271Z","parent_msg_id":"3ec9acc0-c82b-4c10-8672-cd56f5d4dcda"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 15, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9a8ff63d-15cb-4938-9de9-ac3bd0dae580"},{"cell_type":"markdown","source":["---\n","### Normalización de nombres para cargue\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"844cba05-2084-4fe0-9eb3-86a2de82b897"},{"cell_type":"code","source":["FORBIDDEN_CHARS = r\"[ ,;{}\\(\\)\\n\\t=]+\"\n","RESERVED = {\n","    \"select\",\"from\",\"where\",\"group\",\"order\",\"by\",\"having\",\"limit\",\"offset\",\n","    \"and\",\"or\",\"not\",\"as\",\"on\",\"join\",\"inner\",\"left\",\"right\",\"full\",\"cross\",\n","    \"desc\",\"asc\",\"table\",\"column\",\"index\",\"view\",\"database\",\"schema\",\"create\",\n","    \"drop\",\"alter\",\"insert\",\"update\",\"delete\",\"merge\",\"into\",\"values\",\"set\",\n","    \"case\",\"when\",\"then\",\"else\",\"end\",\"union\",\"all\",\"distinct\",\"true\",\"false\",\n","    \"null\"\n","}\n","\n","def strip_accents(text: str) -> str:\n","    t = unicodedata.normalize(\"NFKD\", str(text))\n","    return \"\".join([c for c in t if not unicodedata.combining(c)])\n","\n","def clean_identifier(name: str) -> str:\n","    if name is None:\n","        return \"col\"\n","    s = strip_accents(str(name).strip())\n","    s = re.sub(FORBIDDEN_CHARS, \"_\", s)\n","    s = s.replace(\".\", \"_\").replace(\"-\", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n","    s = re.sub(r\"[^0-9a-zA-Z_]\", \"\", s)\n","    s = re.sub(r\"_+\", \"_\", s).strip(\"_\").lower()\n","    if re.match(r\"^[0-9]\", s):\n","        s = \"c_\" + s\n","    if s in RESERVED:\n","        s = s + \"_col\"\n","    if not s:\n","        s = \"col\"\n","    return s[:128]\n","\n","def split_schema_table(table_name: str):\n","    val = str(table_name).strip()\n","    if \".\" in val:\n","        s, t = val.split(\".\", 1)\n","    else:\n","        s, t = \"dbo\", val\n","    return s.strip(), t.strip()\n","\n","def clean_bronze_table_name(schema: str, table: str) -> str:\n","    schema_c = clean_identifier(schema)\n","    table_c  = clean_identifier(table)\n","    return f\"bronze_{schema_c}_{table_c}\"\n","\n","def build_column_mapping_from_df(columns_df):\n","    cols_norm = {c.lower().strip(): c for c in columns_df.columns}\n","    df = columns_df.rename(columns=cols_norm)\n","\n","    table_col  = next((c for c in df.columns if c in [\"table\",\"table_name\",\"tabla\",\"table_name_full\",\"tabla_origen\"]), None)\n","    column_col = next((c for c in df.columns if c in [\"column\",\"column_name\",\"columna\",\"nombre_columna\"]), None)\n","    if table_col is None or column_col is None:\n","        raise ValueError(f\"Se requieren columnas 'table_name' y 'column_name' (o equivalentes). Encontradas: {list(df.columns)}\")\n","\n","    per_table_seen = defaultdict(set)\n","    mapping = defaultdict(dict)\n","    for _, r in df.iterrows():\n","        schema, table = split_schema_table(r[table_col])\n","        full = f\"{schema}.{table}\"\n","        old  = str(r[column_col]).strip()\n","        new  = clean_identifier(old)\n","\n","        base = new; k = 1\n","        while new in per_table_seen[full]:\n","            k += 1\n","            new = f\"{base}_{k}\"\n","        per_table_seen[full].add(new)\n","\n","        mapping[full][old] = new\n","    return mapping\n","\n","def apply_column_mapping(df_spark, schema: str, table: str, mapping_by_table: dict):\n","    full = f\"{schema}.{table}\"\n","    if full not in mapping_by_table:\n","        return df_spark\n","    mp = mapping_by_table[full]\n","    for old_col, new_col in mp.items():\n","        if old_col in df_spark.columns and old_col != new_col:\n","            df_spark = df_spark.withColumnRenamed(old_col, new_col)\n","    return df_spark\n","\n","def normalize_df_with_mapping_or_clean(df_spark, schema: str, table: str, mapping_by_table: dict):\n","    \"\"\"\n","    1) Aplica mapping por tabla si existe.\n","    2) Limpia cualquier columna restante con clean_identifier para garantizar compatibilidad con Delta.\n","    \"\"\"\n","    df_norm = apply_column_mapping(df_spark, schema, table, mapping_by_table)\n","    fixes = {}\n","    for c in df_norm.columns:\n","        cleaned = clean_identifier(c)\n","        if cleaned != c:\n","            fixes[c] = cleaned\n","    for old_col, new_col in fixes.items():\n","        if old_col in df_norm.columns and old_col != new_col:\n","            df_norm = df_norm.withColumnRenamed(old_col, new_col)\n","    return df_norm\n","\n","def find_col(df_spark, candidates):\n","    \"\"\"\n","    Devuelve el nombre real de la primera columna que coincida con alguno de los candidates (case-insensitive).\n","    Si no encuentra, prueba quitando underscores.\n","    \"\"\"\n","    cols = [c.lower() for c in df_spark.columns]\n","    for cand in candidates:\n","        c = cand.lower()\n","        if c in cols:\n","            return df_spark.columns[cols.index(c)]\n","    cols_rel = [c.replace(\"_\", \"\") for c in cols]\n","    for cand in candidates:\n","        c = cand.lower().replace(\"_\", \"\")\n","        if c in cols_rel:\n","            return df_spark.columns[cols_rel.index(c)]\n","    return None\n","\n","try:\n","    mapping_by_table\n","except NameError:\n","    mapping_by_table = {}  "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":26,"statement_ids":[26],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:35:01.0617484Z","session_start_time":null,"execution_start_time":"2025-09-18T21:35:01.0629322Z","execution_finish_time":"2025-09-18T21:35:01.6671266Z","parent_msg_id":"4e060a37-b2d1-45ee-99c3-ee81f3f4039c"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 26, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4ef93d30-8de8-4f1e-967e-c169355c7485"},{"cell_type":"markdown","source":["---\n","### Ejecución del proceso incremental\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4d3f22c4-21f9-42d1-8969-9f67b2e75192"},{"cell_type":"code","source":["extraction_results = []\n","total_records = 0\n","\n","for table_row in tables_list:\n","    schema = table_row.TABLE_SCHEMA\n","    table = table_row.TABLE_NAME\n","    bronze_table_name = clean_bronze_table_name(schema, table)\n","    \n","    try:\n","        df_extracted, load_type = bronze_loader.extract_table_incremental(schema, table)\n","\n","        if df_extracted is not None and len(df_extracted.columns) > 0:\n","            df_extracted = normalize_df_with_mapping_or_clean(df_extracted, schema, table, mapping_by_table)\n","\n","        if df_extracted is not None:\n","            df_extracted = df_extracted.persist(StorageLevel.MEMORY_AND_DISK)\n","\n","        max_timestamp = None\n","        if df_extracted is not None and df_extracted.count() > 0:\n","            ts_col = find_col(df_extracted, [\"DWCreatedDate\", \"dwcreateddate\", \"dw_created_date\"])\n","            if ts_col:\n","                max_timestamp = df_extracted.agg(fmax(col(ts_col))).collect()[0][0]\n","            if max_timestamp is None:\n","                max_timestamp = datetime.now()\n","\n","        record_count = bronze_loader.save_bronze_table_incremental(\n","            df_extracted, bronze_table_name, load_type\n","        )\n","\n","        bronze_loader.update_execution_control(\n","            f\"{schema}.{table}\", \n","            max_timestamp, \n","            \"success\", \n","            record_count\n","        )\n","\n","        extraction_results.append({\n","            \"source_table\": f\"{schema}.{table}\",\n","            \"bronze_table\": bronze_table_name,\n","            \"record_count\": record_count,\n","            \"load_type\": load_type,\n","            \"status\": \"success\",\n","            \"last_timestamp\": max_timestamp\n","        })\n","        total_records += record_count\n","        print(f\"{bronze_table_name} ({load_type}): {record_count:,} records\")\n","\n","    except Exception as e:\n","        bronze_loader.update_execution_control(f\"{schema}.{table}\", None, \"failed\", 0)\n","        extraction_results.append({\n","            \"source_table\": f\"{schema}.{table}\",\n","            \"bronze_table\": bronze_table_name,\n","            \"record_count\": 0,\n","            \"load_type\": \"failed\",\n","            \"status\": \"failed\",\n","            \"error\": str(e)\n","        })\n","        print(f\"{bronze_table_name}: FAILED - {str(e)}\")\n","    finally:\n","        try:\n","            if df_extracted is not None:\n","                df_extracted.unpersist()\n","        except Exception:\n","            pass\n","    \n","    print(\"-\" * 50)\n","\n","print(\"-\" * 60)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":31,"statement_ids":[31],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:39:45.7740674Z","session_start_time":null,"execution_start_time":"2025-09-18T21:39:45.7751811Z","execution_finish_time":"2025-09-18T21:50:52.1825419Z","parent_msg_id":"027bb5a3-669e-4ec5-a9f6-35eaf72781f0"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 31, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:Primera ejecución incremental para dim.Brands. Usando fecha máxima: 2023-02-10 14:52:07.983000\nINFO:__main__:Carga incremental para [dim].[Brands] desde 2023-02-10 13:52:07.983000\nINFO:__main__:Datos incrementales agregados a bronze_dim_brands: 20 records\nINFO:__main__:Primera ejecución incremental para dim.Budget-Rate. Usando fecha máxima: 2023-02-10 14:52:08.250000\nINFO:__main__:Carga incremental para [dim].[Budget-Rate] desde 2023-02-10 13:52:08.250000\nINFO:__main__:Datos incrementales agregados a bronze_dim_budget_rate: 15 records\nINFO:__main__:Primera ejecución incremental para dim.Customers. Usando fecha máxima: 2023-02-10 14:52:09.250000\nINFO:__main__:Carga incremental para [dim].[Customers] desde 2023-02-10 13:52:09.250000\nINFO:__main__:Datos incrementales agregados a bronze_dim_customers: 3,911 records\nINFO:__main__:Primera ejecución incremental para dim.Employees. Usando fecha máxima: 2023-02-10 14:52:07.963000\nINFO:__main__:Carga incremental para [dim].[Employees] desde 2023-02-10 13:52:07.963000\nINFO:__main__:Datos incrementales agregados a bronze_dim_employees: 893 records\nINFO:__main__:Primera ejecución incremental para dim.Exchange-Rate. Usando fecha máxima: 2023-02-10 14:52:09.243000\nINFO:__main__:Carga incremental para [dim].[Exchange-Rate] desde 2023-02-10 13:52:09.243000\nINFO:__main__:Datos incrementales agregados a bronze_dim_exchange_rate: 57,900 records\nINFO:__main__:Primera ejecución incremental para dim.Invoice-DocType. Usando fecha máxima: 2023-02-10 14:52:08.297000\nINFO:__main__:Carga incremental para [dim].[Invoice-DocType] desde 2023-02-10 13:52:08.297000\nINFO:__main__:Datos incrementales agregados a bronze_dim_invoice_doctype: 5 records\nINFO:__main__:Primera ejecución incremental para dim.Order-DocType. Usando fecha máxima: 2023-02-10 14:52:07.390000\nINFO:__main__:Carga incremental para [dim].[Order-DocType] desde 2023-02-10 13:52:07.390000\nINFO:__main__:Primera ejecución incremental para dim.Order-Status. Usando fecha máxima: 2023-02-10 14:52:08.540000\nINFO:__main__:Carga incremental para [dim].[Order-Status] desde 2023-02-10 13:52:08.540000\nINFO:__main__:Primera ejecución incremental para dim.Products. Usando fecha máxima: 2023-02-10 14:52:16.610000\nINFO:__main__:Carga incremental para [dim].[Products] desde 2023-02-10 13:52:16.610000\nINFO:__main__:Primera ejecución incremental para dim.Regions. Usando fecha máxima: 2023-02-10 14:52:09.130000\nINFO:__main__:Carga incremental para [dim].[Regions] desde 2023-02-10 13:52:09.130000\nINFO:__main__:Primera ejecución incremental para fact.Budget. Usando fecha máxima: 2023-02-10 14:52:38.713000\nINFO:__main__:Carga incremental para [fact].[Budget] desde 2023-02-10 13:52:38.713000\nINFO:__main__:Datos incrementales agregados a bronze_fact_budget: 2,947,811 records\nINFO:__main__:Primera ejecución incremental para fact.Forecast. Usando fecha máxima: 2023-02-10 14:52:06.370000\nINFO:__main__:Carga incremental para [fact].[Forecast] desde 2023-02-10 13:52:06.370000\nINFO:__main__:Primera ejecución incremental para fact.Invoices. Usando fecha máxima: 2023-02-10 15:02:04.983000\nINFO:__main__:Carga incremental para [fact].[Invoices] desde 2023-02-10 14:02:04.983000\nINFO:__main__:Datos incrementales agregados a bronze_fact_invoices: 18,459,441 records\nINFO:__main__:Primera ejecución incremental para fact.Orders. Usando fecha máxima: 2023-02-10 14:59:41.890000\nINFO:__main__:Carga incremental para [fact].[Orders] desde 2023-02-10 13:59:41.890000\n"]},{"output_type":"stream","name":"stdout","text":["bronze_dim_brands (incremental): 20 records\n--------------------------------------------------\nbronze_dim_customers (incremental): 3,911 records\n--------------------------------------------------\nbronze_dim_employees (incremental): 893 records\n--------------------------------------------------\nbronze_dim_order_doctype (incremental): 4 records\n--------------------------------------------------\nbronze_dim_order_status (incremental): 6 records\n--------------------------------------------------\nbronze_dim_products (incremental): 256,293 records\n--------------------------------------------------\nbronze_dim_regions (incremental): 181 records\n--------------------------------------------------\nbronze_fact_forecast (incremental): 5,197 records\n--------------------------------------------------\nbronze_fact_orders (incremental): 16,910,069 records\n--------------------------------------------------\n------------------------------------------------------------\n"]}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"87862b56-0314-4f4f-8e69-30cb40aef2c0"},{"cell_type":"markdown","source":["---\n","### Log de ejecución mejorado\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8c45767d-f027-4d11-8fe0-d00cfae31543"},{"cell_type":"code","source":["spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\n","\n","execution_log_data = [(\n","    execution_date,\n","    \"bronze_incremental_load_azure\",\n","    datetime.now(),\n","    \"completed\" if all(r[\"status\"] == \"success\" for r in extraction_results) else \"completed_with_errors\",\n","    \"bronze\",\n","    \"incremental\", \n","    total_records,\n","    len([r for r in extraction_results if r[\"status\"] == \"success\"]),\n","    len([r for r in extraction_results if r[\"status\"] == \"failed\"]),\n","    len([r for r in extraction_results if r.get(\"load_type\") == \"initial\"]),\n","    len([r for r in extraction_results if r.get(\"load_type\") == \"incremental\"]),\n","    str(extraction_results)[:1000]\n",")]\n","\n","execution_log_schema = StructType([\n","    StructField(\"execution_id\", StringType(), True),\n","    StructField(\"pipeline_name\", StringType(), True),\n","    StructField(\"execution_timestamp\", TimestampType(), True),\n","    StructField(\"status\", StringType(), True),\n","    StructField(\"layer\", StringType(), True),\n","    StructField(\"load_type\", StringType(), True),\n","    StructField(\"total_records\", LongType(), True),\n","    StructField(\"successful_tables\", IntegerType(), True),\n","    StructField(\"failed_tables\", IntegerType(), True),\n","    StructField(\"initial_loads\", IntegerType(), True),\n","    StructField(\"incremental_loads\", IntegerType(), True),\n","    StructField(\"details\", StringType(), True)\n","])\n","\n","execution_log = spark.createDataFrame(execution_log_data, execution_log_schema)\n","\n","execution_log.write \\\n","    .format(\"delta\") \\\n","    .mode(\"append\") \\\n","    .option(\"mergeSchema\", \"true\") \\\n","    .saveAsTable(\"bronze_execution_log\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":32,"statement_ids":[32],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:52:27.9488059Z","session_start_time":null,"execution_start_time":"2025-09-18T21:52:27.9500403Z","execution_finish_time":"2025-09-18T21:52:31.9273444Z","parent_msg_id":"34adf654-ead2-45ef-ba5a-23fa2bd625e2"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 32, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"99c67dfa-334c-49d2-88e3-071dcd1e9114"},{"cell_type":"markdown","source":["---\n","### Resumen del proceso incremental\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0689d0f2-4198-4027-b16c-f915dbfa46ff"},{"cell_type":"code","source":["successful_loads = len([r for r in extraction_results if r[\"status\"] == \"success\"])\n","failed_loads = len([r for r in extraction_results if r[\"status\"] == \"failed\"])\n","initial_loads = len([r for r in extraction_results if r.get(\"load_type\") == \"initial\"])\n","incremental_loads = len([r for r in extraction_results if r.get(\"load_type\") == \"incremental\"])\n","\n","execution_summary = {\n","    \"status\": \"completed\" if failed_loads == 0 else \"completed_with_errors\",\n","    \"successful_tables\": successful_loads,\n","    \"failed_tables\": failed_loads,\n","    \"initial_loads\": initial_loads,\n","    \"incremental_loads\": incremental_loads,\n","    \"total_records\": total_records,\n","    \"execution_date\": execution_date,   \n","    \"data_source\": \"azure_sql_database\",\n","    \"load_type\": \"incremental\"\n","}\n","\n","print(\"INCREMENTAL EXTRACTION SUMMARY:\")\n","print(f\"Successful extractions: {successful_loads}\")\n","print(f\"  - Initial loads: {initial_loads}\")\n","print(f\"  - Incremental loads: {incremental_loads}\")\n","print(f\"Failed extractions: {failed_loads}\")\n","print(f\"Total records extracted: {total_records:,}\")\n","\n","if successful_loads > 0:\n","    print(\"\\nDetalle de cargas exitosas:\")\n","    for result in extraction_results:\n","        if result[\"status\"] == \"success\":\n","            print(f\"  {result['bronze_table']} ({result['load_type']}): {result['record_count']:,} records\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":33,"statement_ids":[33],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:52:30.4649474Z","session_start_time":null,"execution_start_time":"2025-09-18T21:52:31.9294535Z","execution_finish_time":"2025-09-18T21:52:32.2645256Z","parent_msg_id":"9d5b27f5-7c34-4742-809d-87cdbd31d742"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 33, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INCREMENTAL EXTRACTION SUMMARY:\nSuccessful extractions: 14\n  - Initial loads: 0\n  - Incremental loads: 14\nFailed extractions: 0\nTotal records extracted: 38,641,746\n\nDetalle de cargas exitosas:\n  bronze_dim_brands (incremental): 20 records\n  bronze_dim_budget_rate (incremental): 15 records\n  bronze_dim_customers (incremental): 3,911 records\n  bronze_dim_employees (incremental): 893 records\n  bronze_dim_exchange_rate (incremental): 57,900 records\n  bronze_dim_invoice_doctype (incremental): 5 records\n  bronze_dim_order_doctype (incremental): 4 records\n  bronze_dim_order_status (incremental): 6 records\n  bronze_dim_products (incremental): 256,293 records\n  bronze_dim_regions (incremental): 181 records\n  bronze_fact_budget (incremental): 2,947,811 records\n  bronze_fact_forecast (incremental): 5,197 records\n  bronze_fact_invoices (incremental): 18,459,441 records\n  bronze_fact_orders (incremental): 16,910,069 records\n"]}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"be55b704-5747-4f10-a136-f1df3d68e734"},{"cell_type":"markdown","source":["---\n","### Optimización post-carga\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5236d3ae-5590-4c8d-ab6b-348b669762a8"},{"cell_type":"markdown","source":["### Objetivo\n","Aplicar el comando `OPTIMIZE` de **Delta Lake** a todas las tablas que fueron cargadas de forma **incremental y exitosa**, con el fin de **mejorar el rendimiento de lectura** y reducir la fragmentación de archivos.\n","\n","---\n","\n","### Funcionamiento\n","\n","1. **Recorrido de resultados**  \n","   Se recorren los registros de `extraction_results` que representan cada tabla procesada.  \n","\n","2. **Filtrado de tablas**  \n","   Se seleccionan únicamente las tablas con:  \n","   - `status = \"success\"` → cargas exitosas.  \n","   - `load_type = \"incremental\"` → únicamente cargas incrementales.  \n","\n","3. **Optimización con Delta Lake**  \n","   - Se ejecuta `spark.sql(\"OPTIMIZE <tabla>\")`.  \n","   - Este comando **compacta pequeños archivos Parquet** en menos archivos de mayor tamaño.  \n","   - Resultado: consultas más rápidas y menor latencia en análisis.  \n","\n","4. **Manejo de errores**  \n","   - Si alguna optimización falla (por permisos, tabla inexistente, etc.), se captura la excepción y se imprime el error.  \n","\n","5. **Finalización**  \n","   - Al concluir el ciclo, se imprime que el proceso de carga incremental ha finalizado.  \n","\n","---\n","\n","### Beneficio\n","El uso de `OPTIMIZE` es fundamental en procesos incrementales porque:  \n","- Reduce el número de archivos pequeños generados en cada carga.  \n","- Mejora significativamente la eficiencia de consultas en tablas Delta.  \n","- Prepara las tablas para un mejor rendimiento en análisis posteriores. \n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0d2bab1c-994c-4fad-baf6-e8eb360197b3"},{"cell_type":"code","source":["for result in extraction_results:\n","    if result[\"status\"] == \"success\" and result[\"load_type\"] == \"incremental\":\n","        try:\n","            spark.sql(f\"OPTIMIZE {result['bronze_table']}\")\n","            print(f\"Optimizada: {result['bronze_table']}\")\n","        except Exception as e:\n","            print(f\"Error optimizando {result['bronze_table']}: {e}\")\n","\n","print(\"Proceso de carga incremental completado.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":34,"statement_ids":[34],"state":"finished","livy_statement_state":"available","session_id":"a5d3d459-5910-450c-9f39-45308fdbc35b","normalized_state":"finished","queued_time":"2025-09-18T21:52:42.8847169Z","session_start_time":null,"execution_start_time":"2025-09-18T21:52:42.8858641Z","execution_finish_time":"2025-09-18T21:54:28.446129Z","parent_msg_id":"97f4b59b-d122-4d2d-a233-15c0302f8281"},"text/plain":"StatementMeta(, a5d3d459-5910-450c-9f39-45308fdbc35b, 34, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Optimizada: bronze_dim_brands\nOptimizada: bronze_dim_budget_rate\nOptimizada: bronze_dim_customers\nOptimizada: bronze_dim_employees\nOptimizada: bronze_dim_exchange_rate\nOptimizada: bronze_dim_invoice_doctype\nOptimizada: bronze_dim_order_doctype\nOptimizada: bronze_dim_order_status\nOptimizada: bronze_dim_products\nOptimizada: bronze_dim_regions\nOptimizada: bronze_fact_budget\nOptimizada: bronze_fact_forecast\nOptimizada: bronze_fact_invoices\nOptimizada: bronze_fact_orders\nProceso de carga incremental completado.\n"]}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"14428ead-11cc-412b-a8f0-48f71e504bed"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"es"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"a934a70f-0792-489f-ad5a-1c636112596a"}],"default_lakehouse":"a934a70f-0792-489f-ad5a-1c636112596a","default_lakehouse_name":"spaceparts_fabric_lh","default_lakehouse_workspace_id":"46a71285-4d57-4c8d-9bf6-2b3c7d697c2a"}}},"nbformat":4,"nbformat_minor":5}