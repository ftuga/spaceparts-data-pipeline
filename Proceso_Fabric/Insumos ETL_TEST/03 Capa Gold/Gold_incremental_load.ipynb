{"cells":[{"cell_type":"markdown","source":["### Gold Layer - Incremental Load Script\n","- Purpose: Create business-ready data marts with applied business logic\n","- Layer: Gold (Business Data Marts)\n","- Load Type: Incremental"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2632ed09-d7db-4c7c-acd8-ea914f880240"},{"cell_type":"markdown","source":["---\n","### Dependencies\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cdfffa27-33df-42f4-9126-559a49bc35a4"},{"cell_type":"code","source":["import os\n","from datetime import datetime, timedelta\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from pyspark.sql.window import Window\n","import logging\n","from pyspark import StorageLevel"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"875e6559-5b8c-407a-a96f-41cffaa6a4fd","normalized_state":"finished","queued_time":"2025-09-19T04:39:20.0878698Z","session_start_time":"2025-09-19T04:39:20.0888323Z","execution_start_time":"2025-09-19T04:39:32.0143093Z","execution_finish_time":"2025-09-19T04:39:32.4297644Z","parent_msg_id":"85012404-5d74-4463-8b89-ec65e114032c"},"text/plain":"StatementMeta(, 875e6559-5b8c-407a-a96f-41cffaa6a4fd, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4f98c30c-a6c4-44c6-97c0-1258eed2218e"},{"cell_type":"markdown","source":["---\n","### Parameters\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"74f439cf-ad5a-4425-9d43-ae31fc40c2ae"},{"cell_type":"code","source":["execution_date = os.environ.get(\"execution_date\", datetime.now().isoformat())\n","lookback_days = int(os.environ.get(\"lookback_days\", \"7\"))  # Default 7 days lookback\n","force_full_refresh = os.environ.get(\"force_full_refresh\", \"false\").lower() == \"true\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"875e6559-5b8c-407a-a96f-41cffaa6a4fd","normalized_state":"finished","queued_time":"2025-09-19T04:39:20.0898022Z","session_start_time":null,"execution_start_time":"2025-09-19T04:39:32.4317953Z","execution_finish_time":"2025-09-19T04:39:32.7170787Z","parent_msg_id":"51b580c3-3432-46f6-8641-324260223ae4"},"text/plain":"StatementMeta(, 875e6559-5b8c-407a-a96f-41cffaa6a4fd, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0d99f9de-9f0a-4f69-87a6-eea1556c4b7b"},{"cell_type":"markdown","source":["---\n","### Configuraciones de optimización\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"96ac98c4-f4a6-44cd-8de5-62cbe27bd417"},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n","spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n","spark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n","spark.conf.set(\"spark.databricks.delta.autoCompact.enabled\", \"true\")\n","spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\n","spark.conf.set(\"spark.databricks.delta.merge.enableLowShuffle\", \"true\")\n","spark.conf.set(\"spark.sql.adaptive.skewJoin.enabled\", \"true\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"875e6559-5b8c-407a-a96f-41cffaa6a4fd","normalized_state":"finished","queued_time":"2025-09-19T04:39:20.0915346Z","session_start_time":null,"execution_start_time":"2025-09-19T04:39:32.7194272Z","execution_finish_time":"2025-09-19T04:39:33.0326567Z","parent_msg_id":"dd025489-ee42-4ecb-9442-f06dd02bb8c1"},"text/plain":"StatementMeta(, 875e6559-5b8c-407a-a96f-41cffaa6a4fd, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0fd38ec0-4b66-4bcb-88cf-831c4ac9f841"},{"cell_type":"markdown","source":["---\n","### Fecha de corte\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"610bd877-6412-4520-91d3-ba9c9c0f96e5"},{"cell_type":"code","source":["watermark_date = (datetime.now() - timedelta(days=lookback_days)).strftime('%Y-%m-%d')\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","logger.info(f\"Incremental processing parameters:\")\n","logger.info(f\"  Execution Date: {execution_date}\")\n","logger.info(f\"  Lookback Days: {lookback_days}\")\n","logger.info(f\"  Watermark Date: {watermark_date}\")\n","logger.info(f\"  Force Full Refresh: {force_full_refresh}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"875e6559-5b8c-407a-a96f-41cffaa6a4fd","normalized_state":"finished","queued_time":"2025-09-19T04:39:20.0933406Z","session_start_time":null,"execution_start_time":"2025-09-19T04:39:33.035145Z","execution_finish_time":"2025-09-19T04:39:33.3371013Z","parent_msg_id":"dea524fc-0d34-4176-a2c8-87781711abe1"},"text/plain":"StatementMeta(, 875e6559-5b8c-407a-a96f-41cffaa6a4fd, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:Incremental processing parameters:\nINFO:__main__:  Execution Date: 2025-09-19T04:39:32.525736\nINFO:__main__:  Lookback Days: 7\nINFO:__main__:  Watermark Date: 2025-09-12\nINFO:__main__:  Force Full Refresh: False\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bee8da34-387b-45c1-a4eb-eb585d683636"},{"cell_type":"markdown","source":["---\n","### Reglas de negocio\n","---\n","14 Silver tables → 5 Gold semantic models + business views"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1b18f884-c1de-4ea1-b5ec-443eb1cee298"},{"cell_type":"code","source":["class IncrementalUtils:\n","    @staticmethod\n","    def get_last_execution_watermark(table_name):\n","        try:\n","            last_execution = spark.sql(f\"\"\"\n","                SELECT MAX(execution_timestamp) as last_execution\n","                FROM gold_execution_log \n","                WHERE pipeline_name LIKE '%{table_name}%' \n","                AND status = 'success'\n","            \"\"\").collect()[0]['last_execution']\n","            \n","            if last_execution:\n","                return last_execution.strftime('%Y-%m-%d %H:%M:%S')\n","            else:\n","                return '1900-01-01 00:00:00'  \n","        except:\n","            return '1900-01-01 00:00:00'\n","    \n","    @staticmethod\n","    def table_exists(table_name):\n","        try:\n","            spark.sql(f\"DESCRIBE TABLE {table_name}\")\n","            return True\n","        except:\n","            return False\n","    \n","    @staticmethod\n","    def get_changed_keys(source_table, watermark_column, watermark_value, key_column):\n","        try:\n","            changed_df = spark.sql(f\"\"\"\n","                SELECT DISTINCT {key_column}\n","                FROM {source_table}\n","                WHERE {watermark_column} >= '{watermark_value}'\n","            \"\"\")\n","            return changed_df\n","        except Exception as e:\n","            logger.warning(f\"No se pudieron obtener las claves modificadas para {source_table}: {e}\")\n","            return None\n","\n","class GoldIncrementalProcessor:\n","    def __init__(self, spark_session):\n","        self.spark = spark_session\n","        self.utils = IncrementalUtils()\n","        \n","    def merge_gold_dim_customer_incremental(self):\n","        try:\n","            logger.info(\"Procesando gold_dim_customer incremental\")\n","            if not self.utils.table_exists(\"gold_dim_customer\") or force_full_refresh:\n","                logger.info(\"La tabla destino no existe o se forzó el refresh, ejecutando carga completa\")\n","                return self._create_gold_dim_customer_full()\n","            \n","            last_execution = self.utils.get_last_execution_watermark(\"gold_dim_customer\")\n","            changed_customers = self.utils.get_changed_keys(\n","                \"silver_dim_customers\", \"silver_created_date\", last_execution, \"customer_key\"\n","            )\n","            \n","            if changed_customers is None or changed_customers.count() == 0:\n","                logger.info(\"No se detectaron cambios en la dimensión de clientes\")\n","                return 0\n","            \n","            customers_df = self.spark.table(\"silver_dim_customers\")\n","            regions_df = self.spark.table(\"silver_dim_regions\")\n","            employees_df = self.spark.table(\"silver_dim_employees\")\n","            incremental_customer = customers_df.alias(\"c\") \\\n","                .join(changed_customers.alias(\"ch\"), col(\"c.customer_key\") == col(\"ch.customer_key\"), \"inner\") \\\n","                .join(regions_df.alias(\"r\"), col(\"c.station\") == col(\"r.station\"), \"left\") \\\n","                .join(employees_df.filter(col(\"role\") == \"Account Manager\").alias(\"am\"), \n","                      col(\"c.account_manager\") == col(\"am.employee_name\"), \"left\") \\\n","                .join(employees_df.filter(col(\"role\") == \"Key Account Manager\").alias(\"kam\"), \n","                      col(\"c.key_account_manager\") == col(\"kam.employee_name\"), \"left\") \\\n","                .select(\n","                    col(\"c.customer_key\"),\n","                    col(\"c.customer_sold_to_name\"),\n","                    col(\"c.account_name\"),\n","                    col(\"c.key_account_name\"),\n","\n","                    # Atributos para segmentación\n","                    col(\"c.transaction_type\"),\n","                    col(\"c.account_type\"),\n","\n","                    # Geografía\n","                    col(\"r.system\").alias(\"customer_system\"),\n","                    col(\"r.interplanetary_region\"),\n","                    col(\"r.territory\"),\n","                    col(\"r.station\"),\n","                    col(\"r.tax_rate\"),\n","\n","                    # Equipo de ventas\n","                    col(\"c.account_manager\"),\n","                    col(\"c.key_account_manager\"),\n","                    col(\"am.employee_email\").alias(\"account_manager_email\"),\n","                    col(\"kam.employee_email\").alias(\"key_account_manager_email\"),\n","                    \n","                    current_timestamp().alias(\"gold_created_date\"),\n","                    lit(execution_date).alias(\"gold_execution_id\")\n","                )\n","            \n","            incremental_customer.createOrReplaceTempView(\"temp_incremental_customer\")\n","            \n","            self.spark.sql(f\"\"\"\n","                MERGE INTO gold_dim_customer AS target\n","                USING temp_incremental_customer AS source\n","                ON target.customer_key = source.customer_key\n","                WHEN MATCHED THEN UPDATE SET *\n","                WHEN NOT MATCHED THEN INSERT *\n","            \"\"\")\n","            \n","            record_count = incremental_customer.count()\n","            logger.info(f\"INCREMENTAL gold_dim_customer: {record_count:,} registros procesados\")\n","            return record_count\n","            \n","        except Exception as e:\n","            logger.error(f\"Error en merge incremental gold_dim_customer: {str(e)}\")\n","            raise e\n","    \n","    def merge_gold_dim_product_incremental(self):\n","        try:\n","            logger.info(\"Procesando gold_dim_product incremental\")\n","            \n","            if not self.utils.table_exists(\"gold_dim_product\") or force_full_refresh:\n","                logger.info(\"La tabla destino no existe o se forzó el refresh, ejecutando carga completa\")\n","                return self._create_gold_dim_product_full()\n","            \n","            last_execution = self.utils.get_last_execution_watermark(\"gold_dim_product\")\n","            \n","            changed_products = self.utils.get_changed_keys(\n","                \"silver_dim_products\", \"silver_created_date\", last_execution, \"product_key\"\n","            )\n","            \n","            if changed_products is None or changed_products.count() == 0:\n","                logger.info(\"No se detectaron cambios en la dimensión de productos\")\n","                return 0\n","            \n","            products_df = self.spark.table(\"silver_dim_products\")\n","            brands_df = self.spark.table(\"silver_dim_brands\")\n","            \n","            incremental_product = products_df.alias(\"p\") \\\n","                .join(changed_products.alias(\"ch\"), col(\"p.product_key\") == col(\"ch.product_key\"), \"inner\") \\\n","                .join(brands_df.alias(\"b\"), col(\"p.sub_brand_name\") == col(\"b.sub_brand\"), \"left\") \\\n","                .select(\n","                    # Llaves\n","                    col(\"p.product_key\"),\n","                    col(\"p.product_name\"),\n","                    col(\"p.type\").alias(\"product_type\"),\n","                    col(\"p.subtype\").alias(\"product_subtype\"),\n","\n","                    # Atributos físicos\n","                    col(\"p.ship_class_for_part\"),\n","                    col(\"p.weight_tonnes\"),\n","                    col(\"p.color\"),\n","                    col(\"p.material\"),\n","\n","                    # Jerarquía de marca\n","                    col(\"b.flagship\").alias(\"brand_flagship\"),\n","                    col(\"b.class\").alias(\"brand_class\"),\n","                    col(\"b.brand\"),\n","                    col(\"p.sub_brand_name\"),\n","\n","                    # Responsables\n","                    col(\"p.product_business_line_leader\"),\n","                    col(\"b.product_brand_vp\"),\n","                    \n","                    current_timestamp().alias(\"gold_created_date\"),\n","                    lit(execution_date).alias(\"gold_execution_id\")\n","                )\n","            \n","            incremental_product.createOrReplaceTempView(\"temp_incremental_product\")\n","            \n","            self.spark.sql(f\"\"\"\n","                MERGE INTO gold_dim_product AS target\n","                USING temp_incremental_product AS source\n","                ON target.product_key = source.product_key\n","                WHEN MATCHED THEN UPDATE SET *\n","                WHEN NOT MATCHED THEN INSERT *\n","            \"\"\")\n","            \n","            record_count = incremental_product.count()\n","            logger.info(f\"INCREMENTAL gold_dim_product: {record_count:,} registros procesados\")\n","            return record_count\n","            \n","        except Exception as e:\n","            logger.error(f\"Error en merge incremental gold_dim_product: {str(e)}\")\n","            raise e\n","\n","    def merge_gold_fact_sales_incremental(self):\n","        try:\n","            logger.info(\"Procesando gold_fact_sales incremental\")\n","            \n","            if not self.utils.table_exists(\"gold_fact_sales\") or force_full_refresh:\n","                logger.info(\"La tabla destino no existe o se forzó el refresh, ejecutando carga completa\")\n","                return self._create_gold_fact_sales_full()\n","            \n","            # Obtener datos de facturas recientes/modificadas\n","            invoices_df = self.spark.table(\"silver_fact_invoices\")\n","            budget_rate_df = self.spark.table(\"silver_dim_budget_rate\")\n","            doc_types_df = self.spark.table(\"silver_dim_invoice_doctype\")\n","            \n","            # Filtrar solo facturas recientes\n","            recent_invoices = invoices_df.filter(\n","                col(\"silver_created_date\") >= watermark_date\n","            )\n","            \n","            if recent_invoices.count() == 0:\n","                logger.info(\"No hay facturas recientes para procesar\")\n","                return 0\n","            \n","            # Aplicar la misma lógica SIMPLIFICADA del full load\n","            incremental_sales = recent_invoices.alias(\"i\") \\\n","                .join(budget_rate_df.alias(\"br\"), \n","                      col(\"i.local_currency\") == col(\"br.from_currency\"), \"left\") \\\n","                .join(doc_types_df.alias(\"dt\"), \n","                      col(\"i.billing_document_type_code\") == col(\"dt.billing_document_type_code\"), \"left\") \\\n","                .select(\n","                    # Llaves existentes\n","                    col(\"i.customer_key\"),\n","                    col(\"i.product_key\"),\n","                    \n","                    # Fechas como DATE (simplificado)\n","                    to_date(col(\"i.billing_date\")).alias(\"billing_date\"),\n","                    to_date(col(\"i.ship_date\")).alias(\"ship_date\"),\n","\n","                    # Identificadores\n","                    col(\"i.billing_document_number\").alias(\"invoice_number\"),\n","                    col(\"i.billing_document_line_item_number\").alias(\"line_item\"),\n","\n","                    # Valores en EUR (conversión única, simplificado)\n","                    (col(\"i.net_invoice_value\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"sales_eur\"),\n","                    (col(\"i.net_invoice_cogs\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"cogs_eur\"),\n","                    (col(\"i.delivery_cost\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"delivery_cost_eur\"),\n","                    (col(\"i.freight\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"freight_eur\"),\n","                    (col(\"i.taxes_commercial_fees\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"taxes_eur\"),\n","\n","                    # Cantidad\n","                    col(\"i.net_invoice_quantity\").alias(\"quantity\"),\n","\n","                    # Indicador simple\n","                    col(\"i.otd_indicator\").cast(\"boolean\").alias(\"on_time_delivery\"),\n","                    \n","                    # Categorización de documentos (simplificado)\n","                    when(col(\"dt.group_col\") == \"Invoice\", lit(\"Sale\"))\n","                    .when(col(\"dt.group_col\") == \"Adjustment\", lit(\"Adjustment\"))\n","                    .when(col(\"dt.group_col\").isNull(), lit(\"Unclassified\"))\n","                    .otherwise(col(\"dt.group_col\")).alias(\"document_category\"),\n","                    \n","                    # Metadatos para trazabilidad\n","                    col(\"i.billing_document_type_code\").alias(\"source_doc_type_code\"),\n","                    col(\"dt.text\").alias(\"document_type_description\"),\n","                    \n","                    current_timestamp().alias(\"gold_created_date\"),\n","                    lit(execution_date).alias(\"gold_execution_id\")\n","                )\n","            \n","            incremental_sales.createOrReplaceTempView(\"temp_incremental_sales\")\n","            \n","            # MERGE\n","            self.spark.sql(f\"\"\"\n","                MERGE INTO gold_fact_sales AS target\n","                USING temp_incremental_sales AS source\n","                ON target.customer_key = source.customer_key \n","                   AND target.product_key = source.product_key \n","                   AND target.billing_date = source.billing_date\n","                   AND target.invoice_number = source.invoice_number\n","                   AND target.line_item = source.line_item\n","                WHEN MATCHED THEN UPDATE SET *\n","                WHEN NOT MATCHED THEN INSERT *\n","            \"\"\")\n","            \n","            record_count = incremental_sales.count()\n","            logger.info(f\"INCREMENTAL gold_fact_sales: {record_count:,} registros procesados\")\n","            return record_count\n","            \n","        except Exception as e:\n","            logger.error(f\"Error en merge incremental gold_fact_sales: {str(e)}\")\n","            raise e\n","\n","    def merge_gold_fact_orders_incremental(self):\n","        try:\n","            logger.info(\"Procesando gold_fact_orders incremental\")\n","            \n","            if not self.utils.table_exists(\"gold_fact_orders\") or force_full_refresh:\n","                logger.info(\"La tabla destino no existe o se forzó el refresh, ejecutando carga completa\")\n","                return self._create_gold_fact_orders_full()\n","            \n","            # Obtener datos de órdenes recientes/modificadas\n","            orders_df = self.spark.table(\"silver_fact_orders\")\n","            budget_rate_df = self.spark.table(\"silver_dim_budget_rate\")\n","            \n","            # Filtrar solo órdenes recientes\n","            recent_orders = orders_df.filter(\n","                col(\"silver_created_date\") >= watermark_date\n","            )\n","            \n","            if recent_orders.count() == 0:\n","                logger.info(\"No hay órdenes recientes para procesar\")\n","                return 0\n","            \n","            # Aplicar la misma lógica del full load\n","            incremental_orders = recent_orders.alias(\"o\") \\\n","                .join(budget_rate_df.alias(\"br\"), col(\"o.local_currency\") == col(\"br.from_currency\"), \"left\") \\\n","                .select(\n","                    # Llaves existentes\n","                    col(\"o.customer_key\"),\n","                    col(\"o.product_key\"),\n","\n","                    # Fechas como DATE\n","                    to_date(col(\"o.order_date\")).alias(\"order_date\"),\n","                    to_date(col(\"o.ship_date\")).alias(\"ship_date\"),\n","                    to_date(col(\"o.request_goods_receipt_date\")).alias(\"requested_date\"),\n","\n","                    # Identificadores\n","                    col(\"o.sales_order_document_number\").alias(\"order_number\"),\n","                    col(\"o.sales_order_document_line_item_number\").alias(\"line_item\"),\n","\n","                    # Valores en EUR\n","                    (col(\"o.net_order_value\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"order_value_eur\"),\n","                    col(\"o.net_order_quantity\").alias(\"quantity\"),\n","\n","                    # Status\n","                    col(\"o.sales_order_document_line_item_status\").alias(\"order_status\"),\n","                    \n","                    current_timestamp().alias(\"gold_created_date\"),\n","                    lit(execution_date).alias(\"gold_execution_id\")\n","                )\n","            \n","            incremental_orders.createOrReplaceTempView(\"temp_incremental_orders\")\n","            \n","            # MERGE 2\n","            self.spark.sql(f\"\"\"\n","                MERGE INTO gold_fact_orders AS target\n","                USING temp_incremental_orders AS source\n","                ON target.customer_key = source.customer_key \n","                   AND target.product_key = source.product_key \n","                   AND target.order_date = source.order_date\n","                   AND target.order_number = source.order_number\n","                   AND target.line_item = source.line_item\n","                WHEN MATCHED THEN UPDATE SET *\n","                WHEN NOT MATCHED THEN INSERT *\n","            \"\"\")\n","            \n","            record_count = incremental_orders.count()\n","            logger.info(f\"INCREMENTAL gold_fact_orders: {record_count:,} registros procesados\")\n","            return record_count\n","            \n","        except Exception as e:\n","            logger.error(f\"Error en merge incremental gold_fact_orders: {str(e)}\")\n","            raise e\n","\n","    def merge_gold_fact_budget_incremental(self):\n","        try:\n","            logger.info(\"Procesando gold_fact_budget incremental\")\n","            \n","            if not self.utils.table_exists(\"gold_fact_budget\") or force_full_refresh:\n","                logger.info(\"La tabla destino no existe o se forzó el refresh, ejecutando carga completa\")\n","                return self._create_gold_fact_budget_full()\n","            \n","            # Obtener datos de presupuesto recientes/modificados\n","            budget_df = self.spark.table(\"silver_fact_budget\")\n","            \n","            # Filtrar solo presupuestos recientes\n","            recent_budget = budget_df.filter(\n","                col(\"silver_created_date\") >= watermark_date\n","            )\n","            \n","            if recent_budget.count() == 0:\n","                logger.info(\"No hay datos de presupuesto recientes para procesar\")\n","                return 0\n","            \n","            # Aplicar la misma lógica del full load\n","            incremental_budget = recent_budget.select(\n","                # Llaves existentes\n","                col(\"customer_key\"),\n","                col(\"product_key\"),\n","\n","                # Fecha como DATE\n","                to_date(col(\"month\")).alias(\"budget_month\"),\n","\n","                # Valor en EUR (ya viene en EUR desde silver)\n","                col(\"total_budget\").alias(\"budget_eur\"),\n","                \n","                current_timestamp().alias(\"gold_created_date\"),\n","                lit(execution_date).alias(\"gold_execution_id\")\n","            ).filter(col(\"budget_month\").isNotNull())\n","            \n","            incremental_budget.createOrReplaceTempView(\"temp_incremental_budget\")\n","            \n","            # MERGE3\n","            self.spark.sql(f\"\"\"\n","                MERGE INTO gold_fact_budget AS target\n","                USING temp_incremental_budget AS source\n","                ON target.customer_key = source.customer_key \n","                   AND target.product_key = source.product_key \n","                   AND target.budget_month = source.budget_month\n","                WHEN MATCHED THEN UPDATE SET *\n","                WHEN NOT MATCHED THEN INSERT *\n","            \"\"\")\n","            \n","            record_count = incremental_budget.count()\n","            logger.info(f\"INCREMENTAL gold_fact_budget: {record_count:,} registros procesados\")\n","            return record_count\n","            \n","        except Exception as e:\n","            logger.error(f\"Error en merge incremental gold_fact_budget: {str(e)}\")\n","            raise e\n","\n","    # Logs\n","        logger.info(\"Ejecutando carga completa para gold_dim_customer\")\n","        \n","        customers_df = self.spark.table(\"silver_dim_customers\")\n","        regions_df = self.spark.table(\"silver_dim_regions\")\n","        employees_df = self.spark.table(\"silver_dim_employees\")\n","\n","        consolidated_customer = (\n","            customers_df.alias(\"c\")\n","            .join(regions_df.alias(\"r\"), col(\"c.station\") == col(\"r.station\"), \"left\")\n","            .join(\n","                employees_df.filter(col(\"role\") == \"Account Manager\").alias(\"am\"),\n","                col(\"c.account_manager\") == col(\"am.employee_name\"), \"left\"\n","            )\n","            .join(\n","                employees_df.filter(col(\"role\") == \"Key Account Manager\").alias(\"kam\"),\n","                col(\"c.key_account_manager\") == col(\"kam.employee_name\"), \"left\"\n","            )\n","            .select(\n","                # Llaves\n","                col(\"c.customer_key\"),\n","                col(\"c.customer_sold_to_name\"),\n","                col(\"c.account_name\"),\n","                col(\"c.key_account_name\"),\n","\n","                # Atributos para segmentación\n","                col(\"c.transaction_type\"),\n","                col(\"c.account_type\"),\n","\n","                # Geografía\n","                col(\"r.system\").alias(\"customer_system\"),\n","                col(\"r.interplanetary_region\"),\n","                col(\"r.territory\"),\n","                col(\"r.station\"),\n","                col(\"r.tax_rate\"),\n","\n","                # Equipo de ventas\n","                col(\"c.account_manager\"),\n","                col(\"c.key_account_manager\"),\n","                col(\"am.employee_email\").alias(\"account_manager_email\"),\n","                col(\"kam.employee_email\").alias(\"key_account_manager_email\")\n","            )\n","        )\n","\n","        record_count = consolidated_customer.count()\n","        consolidated_customer.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"gold_dim_customer\")\n","        return record_count\n","    \n","    def _create_gold_dim_product_full(self):\n","        logger.info(\"Ejecutando carga completa para gold_dim_product\")\n","        \n","        products_df = self.spark.table(\"silver_dim_products\")\n","        brands_df = self.spark.table(\"silver_dim_brands\")\n","\n","        consolidated_product = (\n","            products_df.alias(\"p\")\n","            .join(brands_df.alias(\"b\"), col(\"p.sub_brand_name\") == col(\"b.sub_brand\"), \"left\")\n","            .select(\n","                # Llaves\n","                col(\"p.product_key\"),\n","                col(\"p.product_name\"),\n","                col(\"p.type\").alias(\"product_type\"),\n","                col(\"p.subtype\").alias(\"product_subtype\"),\n","\n","                # Atributos físicos\n","                col(\"p.ship_class_for_part\"),\n","                col(\"p.weight_tonnes\"),\n","                col(\"p.color\"),\n","                col(\"p.material\"),\n","\n","                # Jerarquía de marca\n","                col(\"b.flagship\").alias(\"brand_flagship\"),\n","                col(\"b.class\").alias(\"brand_class\"),\n","                col(\"b.brand\"),\n","                col(\"p.sub_brand_name\"),\n","\n","                # Responsables\n","                col(\"p.product_business_line_leader\"),\n","                col(\"b.product_brand_vp\")\n","            )\n","        )\n","\n","        record_count = consolidated_product.count()\n","        consolidated_product.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"gold_dim_product\")\n","        return record_count\n","    \n","    def _create_gold_fact_sales_full(self):\n","        logger.info(\"Ejecutando carga completa para gold_fact_sales\")\n","        \n","        invoices_df = self.spark.table(\"silver_fact_invoices\")\n","        budget_rate_df = self.spark.table(\"silver_dim_budget_rate\")\n","        doc_types_df = self.spark.table(\"silver_dim_invoice_doctype\")\n","\n","        gold_fact_sales = (\n","            invoices_df.alias(\"i\")\n","            .join(budget_rate_df.alias(\"br\"), col(\"i.local_currency\") == col(\"br.from_currency\"), \"left\")\n","            .join(doc_types_df.alias(\"dt\"), col(\"i.billing_document_type_code\") == col(\"dt.billing_document_type_code\"), \"left\")\n","            .select(\n","                # Llaves existentes\n","                col(\"i.customer_key\"),\n","                col(\"i.product_key\"),\n","                \n","                # Fechas como DATE\n","                to_date(col(\"i.billing_date\")).alias(\"billing_date\"),\n","                to_date(col(\"i.ship_date\")).alias(\"ship_date\"),\n","\n","                # Identificadores\n","                col(\"i.billing_document_number\").alias(\"invoice_number\"),\n","                col(\"i.billing_document_line_item_number\").alias(\"line_item\"),\n","\n","                # Valores en EUR (conversión única)\n","                (col(\"i.net_invoice_value\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"sales_eur\"),\n","                (col(\"i.net_invoice_cogs\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"cogs_eur\"),\n","                (col(\"i.delivery_cost\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"delivery_cost_eur\"),\n","                (col(\"i.freight\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"freight_eur\"),\n","                (col(\"i.taxes_commercial_fees\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"taxes_eur\"),\n","\n","                # Cantidad\n","                col(\"i.net_invoice_quantity\").alias(\"quantity\"),\n","\n","                # Indicador simple\n","                col(\"i.otd_indicator\").cast(\"boolean\").alias(\"on_time_delivery\"),\n","                \n","                # Categorización de documentos\n","                when(col(\"dt.group_col\") == \"Invoice\", lit(\"Sale\"))\n","                .when(col(\"dt.group_col\") == \"Adjustment\", lit(\"Adjustment\"))\n","                .when(col(\"dt.group_col\").isNull(), lit(\"Unclassified\"))\n","                .otherwise(col(\"dt.group_col\")).alias(\"document_category\"),\n","                \n","                # Metadatos para trazabilidad\n","                col(\"i.billing_document_type_code\").alias(\"source_doc_type_code\"),\n","                col(\"dt.text\").alias(\"document_type_description\")\n","            )\n","        )\n","\n","        record_count = gold_fact_sales.count()\n","        gold_fact_sales.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"gold_fact_sales\")\n","        return record_count\n","    \n","    def _create_gold_fact_orders_full(self):\n","        logger.info(\"Ejecutando carga completa para gold_fact_orders\")\n","        \n","        orders_df = self.spark.table(\"silver_fact_orders\")\n","        budget_rate_df = self.spark.table(\"silver_dim_budget_rate\")\n","\n","        gold_fact_orders = (\n","            orders_df.alias(\"o\")\n","            .join(budget_rate_df.alias(\"br\"), col(\"o.local_currency\") == col(\"br.from_currency\"), \"left\")\n","            .select(\n","                # Llaves existentes\n","                col(\"o.customer_key\"),\n","                col(\"o.product_key\"),\n","\n","                # Fechas como DATE\n","                to_date(col(\"o.order_date\")).alias(\"order_date\"),\n","                to_date(col(\"o.ship_date\")).alias(\"ship_date\"),\n","                to_date(col(\"o.request_goods_receipt_date\")).alias(\"requested_date\"),\n","\n","                # Identificadores\n","                col(\"o.sales_order_document_number\").alias(\"order_number\"),\n","                col(\"o.sales_order_document_line_item_number\").alias(\"line_item\"),\n","\n","                # Valores en EUR\n","                (col(\"o.net_order_value\") * coalesce(col(\"br.rate\"), lit(1.0))).alias(\"order_value_eur\"),\n","                col(\"o.net_order_quantity\").alias(\"quantity\"),\n","\n","                # Status\n","                col(\"o.sales_order_document_line_item_status\").alias(\"order_status\")\n","            )\n","        )\n","\n","        record_count = gold_fact_orders.count()\n","        gold_fact_orders.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"gold_fact_orders\")\n","        return record_count\n","    \n","    def _create_gold_fact_budget_full(self):\n","        logger.info(\"Ejecutando carga completa para gold_fact_budget\")\n","        \n","        budget_df = self.spark.table(\"silver_fact_budget\")\n","\n","        gold_fact_budget = (\n","            budget_df.select(\n","                col(\"customer_key\"),\n","                col(\"product_key\"),\n","                to_date(col(\"month\")).alias(\"budget_month\"),\n","                col(\"total_budget\").alias(\"budget_eur\")\n","            )\n","            .filter(col(\"budget_month\").isNotNull())\n","        )\n","\n","        record_count = gold_fact_budget.count()\n","        gold_fact_budget.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"gold_fact_budget\")\n","        return record_count"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"875e6559-5b8c-407a-a96f-41cffaa6a4fd","normalized_state":"finished","queued_time":"2025-09-19T04:39:20.2053237Z","session_start_time":null,"execution_start_time":"2025-09-19T04:39:33.3407877Z","execution_finish_time":"2025-09-19T04:39:33.8262718Z","parent_msg_id":"85cc2436-ccab-4f48-8fab-11dbd0c7bb5e"},"text/plain":"StatementMeta(, 875e6559-5b8c-407a-a96f-41cffaa6a4fd, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ea4b3d68-8531-47a8-a664-414fba3c8996"},{"cell_type":"code","source":["gold_processor = GoldIncrementalProcessor(spark)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"875e6559-5b8c-407a-a96f-41cffaa6a4fd","normalized_state":"finished","queued_time":"2025-09-19T04:39:20.2074575Z","session_start_time":null,"execution_start_time":"2025-09-19T04:39:33.8282133Z","execution_finish_time":"2025-09-19T04:39:34.2274661Z","parent_msg_id":"d3282b0c-e14c-4fee-8de4-7b72968cb791"},"text/plain":"StatementMeta(, 875e6559-5b8c-407a-a96f-41cffaa6a4fd, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c1fc3efe-0351-4e93-8014-fdc0644a593c"},{"cell_type":"markdown","source":["---\n","### Creación de data de negocio\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ea43b6b0-1de5-4cb9-9449-ea27a9ff7562"},{"cell_type":"code","source":["results = []\n","total_records = 0\n","\n","# Procesa incremental dimensions\n","try:\n","    record_count = gold_processor.merge_gold_dim_customer_incremental()\n","    results.append({'table_name': 'gold_dim_customer', 'record_count': record_count, 'status': 'success'})\n","    total_records += record_count\n","except Exception as e:\n","    results.append({'table_name': 'gold_dim_customer', 'record_count': 0, 'status': 'failed', 'error': str(e)})\n","    print(f\"gold_dim_customer: FAILED - {str(e)}\")\n","\n","try:\n","    record_count = gold_processor.merge_gold_dim_product_incremental()\n","    results.append({'table_name': 'gold_dim_product', 'record_count': record_count, 'status': 'success'})\n","    total_records += record_count\n","except Exception as e:\n","    results.append({'table_name': 'gold_dim_product', 'record_count': 0, 'status': 'failed', 'error': str(e)})\n","    print(f\"gold_dim_product: FAILED - {str(e)}\")\n","\n","try:\n","    record_count = gold_processor.merge_gold_dim_date_incremental()\n","    results.append({'table_name': 'gold_dim_date', 'record_count': record_count, 'status': 'success'})\n","    total_records += record_count\n","except Exception as e:\n","    results.append({'table_name': 'gold_dim_date', 'record_count': 0, 'status': 'failed', 'error': str(e)})\n","    print(f\"gold_dim_date: FAILED - {str(e)}\")\n","\n","# Procesa incremental facts\n","try:\n","    record_count = gold_processor.merge_gold_fact_sales_incremental()\n","    results.append({'table_name': 'gold_fact_sales', 'record_count': record_count, 'status': 'success'})\n","    total_records += record_count\n","except Exception as e:\n","    results.append({'table_name': 'gold_fact_sales', 'record_count': 0, 'status': 'failed', 'error': str(e)})\n","    print(f\"gold_fact_sales: FAILED - {str(e)}\")\n","\n","try:\n","    record_count = gold_processor.merge_gold_fact_performance_incremental()\n","    results.append({'table_name': 'gold_fact_performance', 'record_count': record_count, 'status': 'success'})\n","    total_records += record_count\n","except Exception as e:\n","    results.append({'table_name': 'gold_fact_performance', 'record_count': 0, 'status': 'failed', 'error': str(e)})\n","    print(f\"gold_fact_performance: FAILED - {str(e)}\")\n","\n","# Refresca business views\n","try:\n","    gold_processor.refresh_business_semantic_views()\n","    print(\"Business semantic views refreshed\")\n","except Exception as e:\n","    print(f\"Business views refresh failed: {str(e)}\")\n","\n","print(\"-\" * 60)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"875e6559-5b8c-407a-a96f-41cffaa6a4fd","normalized_state":"finished","queued_time":"2025-09-19T04:39:20.2092694Z","session_start_time":null,"execution_start_time":"2025-09-19T04:39:34.2295772Z","execution_finish_time":"2025-09-19T04:42:12.6244692Z","parent_msg_id":"bb93f8db-dc01-4bbe-b711-303fa4ed2ee3"},"text/plain":"StatementMeta(, 875e6559-5b8c-407a-a96f-41cffaa6a4fd, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:Procesando gold_dim_customer incremental\nINFO:__main__:INCREMENTAL gold_dim_customer: 3,911 registros procesados\nINFO:__main__:Procesando gold_dim_product incremental\nINFO:__main__:INCREMENTAL gold_dim_product: 256,293 registros procesados\nINFO:__main__:Procesando gold_dim_date incremental\nINFO:__main__:No hay nuevas fechas para procesar\nINFO:__main__:Procesando gold_fact_sales incremental\nINFO:__main__:No hay facturas recientes para procesar\nINFO:__main__:Procesando gold_fact_performance incremental\n"]},{"output_type":"stream","name":"stdout","text":["Business semantic views refreshed\n------------------------------------------------------------\n"]}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"7a3f738e-f385-490c-8794-d9899ace5865\",\"activityId\":\"875e6559-5b8c-407a-a96f-41cffaa6a4fd\",\"applicationId\":\"application_1758256143541_0001\",\"jobGroupId\":\"9\",\"advices\":{\"info\":1,\"warn\":4}}"}},"id":"c775479a-9d39-4b1c-85b8-6114e4d0bbda"},{"cell_type":"markdown","source":["---\n","### Logs del proceso\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"12a94582-6709-4b03-ac52-dee6c9bbcfde"},{"cell_type":"code","source":["execution_log_data = [(\n","    execution_date,\n","    \"gold_incremental_load_semantic\",\n","    datetime.now(),\n","    \"completed\" if all(r[\"status\"] == \"success\" for r in results) else \"completed_with_errors\",\n","    \"gold\",\n","    \"incremental\",\n","    total_records,\n","    len([r for r in results if r[\"status\"] == \"success\"]),\n","    len([r for r in results if r[\"status\"] == \"failed\"]),\n","    f\"Incremental processing: {lookback_days} days lookback, watermark: {watermark_date}\"\n",")]\n","\n","execution_log_schema = StructType([\n","    StructField(\"execution_id\", StringType(), True),\n","    StructField(\"pipeline_name\", StringType(), True),\n","    StructField(\"execution_timestamp\", TimestampType(), True),\n","    StructField(\"status\", StringType(), True),\n","    StructField(\"layer\", StringType(), True),\n","    StructField(\"load_type\", StringType(), True),\n","    StructField(\"total_records\", LongType(), True),\n","    StructField(\"successful_tables\", IntegerType(), True),\n","    StructField(\"failed_tables\", IntegerType(), True),\n","    StructField(\"details\", StringType(), True)\n","])\n","\n","execution_log = spark.createDataFrame(execution_log_data, execution_log_schema)\n","execution_log.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").saveAsTable(\"gold_execution_log\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"875e6559-5b8c-407a-a96f-41cffaa6a4fd","normalized_state":"finished","queued_time":"2025-09-19T04:39:20.5428653Z","session_start_time":null,"execution_start_time":"2025-09-19T04:42:12.6268912Z","execution_finish_time":"2025-09-19T04:42:17.3904063Z","parent_msg_id":"4e32c537-4201-48e2-b08e-d59c5ee482b4"},"text/plain":"StatementMeta(, 875e6559-5b8c-407a-a96f-41cffaa6a4fd, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bc5e1eaa-b687-458b-9366-73a3315bf830"},{"cell_type":"markdown","source":["---\n","### Resumen del proceso\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4d00c574-12e1-424e-9bc4-9cc4bc933c26"},{"cell_type":"code","source":["successful_loads = len([r for r in results if r[\"status\"] == \"success\"])\n","failed_loads = len([r for r in results if r[\"status\"] == \"failed\"])\n","\n","print(\"=\" * 60)\n","print(\"GOLD INCREMENTAL LAYER SUMMARY:\")\n","print(f\"Successful incremental loads: {successful_loads}/5\")\n","print(f\"Failed incremental loads: {failed_loads}/5\")\n","print(f\"Total records processed: {total_records:,}\")\n","print(f\"Processing window: {lookback_days} days (desde {watermark_date})\")\n","print(f\"Execution Date: {execution_date}\")\n","print(\"=\" * 60)\n","\n","if successful_loads > 0:\n","    print(\"\\nSuccessfully processed Gold tables:\")\n","    for result in results:\n","        if result[\"status\"] == \"success\":\n","            print(f\"  {result['table_name']}: {result['record_count']:,} records\")\n","\n","print(\"\\nOptimizing processed Gold tables...\")\n","for result in results:\n","    if result[\"status\"] == \"success\" and result['record_count'] > 0:\n","        try:\n","            spark.sql(f\"OPTIMIZE {result['table_name']}\")\n","            print(f\"Optimized: {result['table_name']}\")\n","        except Exception as e:\n","            print(f\"Error optimizing {result['table_name']}: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"875e6559-5b8c-407a-a96f-41cffaa6a4fd","normalized_state":"finished","queued_time":"2025-09-19T04:39:21.7141748Z","session_start_time":null,"execution_start_time":"2025-09-19T04:42:17.3924961Z","execution_finish_time":"2025-09-19T04:42:22.4595017Z","parent_msg_id":"e7a6e034-3411-4d22-8777-649795a9026a"},"text/plain":"StatementMeta(, 875e6559-5b8c-407a-a96f-41cffaa6a4fd, 11, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["============================================================\nGOLD INCREMENTAL LAYER SUMMARY:\nSuccessful incremental loads: 5/5\nFailed incremental loads: 0/5\nTotal records processed: 260,204\nProcessing window: 7 days (desde 2025-09-12)\nExecution Date: 2025-09-19T04:39:32.525736\n============================================================\n\nSuccessfully processed Gold tables:\n  gold_dim_customer: 3,911 records\n  gold_dim_product: 256,293 records\n  gold_dim_date: 0 records\n  gold_fact_sales: 0 records\n  gold_fact_performance: 0 records\n\nOptimizing processed Gold tables...\nOptimized: gold_dim_customer\nOptimized: gold_dim_product\n"]}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1796f3c3-3cf6-4bc6-808a-9e3e47f3f7d7"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"es"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"a934a70f-0792-489f-ad5a-1c636112596a"}],"default_lakehouse":"a934a70f-0792-489f-ad5a-1c636112596a","default_lakehouse_name":"spaceparts_fabric_lh","default_lakehouse_workspace_id":"46a71285-4d57-4c8d-9bf6-2b3c7d697c2a"}}},"nbformat":4,"nbformat_minor":5}